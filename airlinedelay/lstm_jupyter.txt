{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lycv4qzjQQEW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import layers, models, Sequential\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "import csv\n",
        "reader = lambda rname: list(csv.reader(open(rname), delimiter=','))\n",
        "writer = lambda wname: csv.writer(open(wname, 'w', newline=''))\n",
        "\n",
        "\n",
        "class RNN:\n",
        "    def __init__(self, rfname, max_features=15000, len_data=50000, len_col=15, output_embedding=128, dropout=0.1,\n",
        "                 output_neuron=1, batch_size=2**5, epochs=30):\n",
        "        # 데이터 불러오기\n",
        "        data = reader(rfname)\n",
        "        self.max_features = max_features\n",
        "        self.len_data = len_data\n",
        "        self.len_col = len_col\n",
        "\n",
        "        self.output_embedding = output_embedding\n",
        "        self.dropout = dropout\n",
        "        self.output_neuron = output_neuron\n",
        "\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "\n",
        "        # feature(x_data)와 result(y_data) 나누기\n",
        "        x_data = np.array([list(map(int, [e for e in elem[:self.len_col]])) for elem in data[:self.len_data]])\n",
        "        y_data = np.array([int(elem[self.len_col]) for elem in data[:self.len_data]])\n",
        "\n",
        "        # 오버샘플링\n",
        "        x_data, y_data = ADASYN(random_state=0).fit_resample(x_data, y_data)\n",
        "\n",
        "        # result(딜레이여부) 원핫인코딩으로 카테고리화\n",
        "        # result가 0,1 밖에 없으므로 생략\n",
        "        #y_data = np_utils.to_categorical(y_data)\n",
        "\n",
        "        # 학습, 테스트 나누기\n",
        "        x_train, y_train,  = x_data[:len(x_data):2], y_data[:len(y_data):2],\n",
        "        x_test, y_test =x_data[1:len(x_data):2], y_data[1:len(y_data):2]\n",
        "\n",
        "        # 이니셜라이징\n",
        "        self.x_train, self.y_train = x_train, y_train\n",
        "        self.x_test, self.y_test = x_test, y_test\n",
        "\n",
        "    def load_model(self):\n",
        "        self.model = load_model(self.model_name)\n",
        "    def save_model(self):\n",
        "        self.model.save('{0}.h5'.format(self.model_name))\n",
        "\n",
        "    def LSTM_Adam(self):\n",
        "        self.model_name = \"LSTM_Adam\"\n",
        "        model = Sequential()\n",
        "        #model.add(layers.Input((self.len_col,)))\n",
        "        model.add(layers.Embedding(self.max_features, self.output_embedding))\n",
        "\n",
        "        model.add(layers.LSTM(self.output_embedding, dropout=self.dropout, recurrent_dropout=self.dropout))\n",
        "        #model.add(layers.LSTM(self.output_embedding, activation='sigmoid'))\n",
        "\n",
        "        model.add(layers.Dense(self.output_neuron))\n",
        "        #model.add(layers.Dense(self.output_neuron, activation='softmax'))\n",
        "\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def LSTM_Adadelta(self):\n",
        "        self.model_name = \"LSTM_Adadelta\"\n",
        "        model = Sequential()\n",
        "        model.add(layers.Embedding(self.max_features, self.output_embedding))\n",
        "        model.add(layers.LSTM(self.output_embedding, activation='sigmoid'))\n",
        "        model.add(layers.Dense(self.output_neuron, activation='softmax'))\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def LSTM_CNN(self):\n",
        "        self.model_name = \"LSTM_CNN\"\n",
        "        model = Sequential()\n",
        "        model.add(layers.Embedding(self.max_features, self.output_embedding))\n",
        "        model.add(layers.Dropout(self.dropout))\n",
        "        model.add(layers.Conv1D(2**8, 4, padding='valid', activation='relu', strides=1))\n",
        "        model.add(layers.MaxPooling1D(pool_size=4))\n",
        "        model.add(layers.LSTM(self.output_embedding))\n",
        "        model.add(layers.Dense(self.output_neuron))\n",
        "        model.add(layers.Activation('sigmoid'))\n",
        "        model.summary()\n",
        "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "\n",
        "        self.model = model\n",
        "\n",
        "    def train_model(self):\n",
        "        print(\"----------------------------------\")\n",
        "        print(\"----------Training Start----------\")\n",
        "        print(\"----------------------------------\")\n",
        "        self.history = self.model.fit(self.x_train, self.y_train,\n",
        "                            batch_size=self.batch_size, epochs=self.epochs,\n",
        "                            validation_data=(self.x_test, self.y_test),\n",
        "                            verbose=2)\n",
        "\n",
        "    def test_model(self):\n",
        "        loss, acc = self.model.evaluate(self.x_test, self.y_test,\n",
        "                                   batch_size=self.batch_size, verbose=2)\n",
        "\n",
        "        print('Test Results : acc={0} // loss={1}'.format(acc, loss))\n",
        "\n",
        "    def loss_graph(self):\n",
        "        y_train_loss = self.history.history['loss']\n",
        "        y_test_loss = self.history.history['val_loss']\n",
        "\n",
        "        x_len = np.arange(len(y_test_loss))\n",
        "\n",
        "        plt.plot(x_len, y_test_loss, marker=',', c='red', label='Test loss')\n",
        "        plt.plot(x_len, y_train_loss, marker=',', c='blue', label='Train loss')\n",
        "\n",
        "        plt.legend(loc='upper right')\n",
        "        plt.grid()\n",
        "        plt.xlabel('epoch')\n",
        "        plt.ylabel('loss')\n",
        "        plt.title(self.model_name)\n",
        "        plt.savefig('{0}.png'.format(self.model_name))\n",
        "        plt.clf()\n",
        "        plt.cla()\n",
        "        plt.close()\n",
        "\n",
        "    def main(self):\n",
        "        self.LSTM_Adam()\n",
        "        self.train_model()\n",
        "        self.test_model()\n",
        "        self.loss_graph()\n",
        "        self.save_model()\n",
        "\n",
        "        self.LSTM_Adadelta()\n",
        "        self.train_model()\n",
        "        self.test_model()\n",
        "        self.loss_graph()\n",
        "        self.save_model()\n",
        "\n",
        "        self.LSTM_CNN()\n",
        "        self.train_model()\n",
        "        self.test_model()\n",
        "        self.loss_graph()\n",
        "        self.save_model()\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    RNN(\"testdata_2.csv\").main()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}